{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are a giant e-commerce company selling plants and pottery. We sell these items on our website as well as offer a 3-month subscription service where users get a new plant-pottery set every month of subscription with all required care instructions.\n",
    "<br><br>\n",
    "Suppose we are running a test comparing the current best model for pricing the items on our website and a new model we think might be better (the Challenger). We run the test showing these two different variants to our users but we realize there is an issue! The model is being shown to different numbers of people on different mobile devices (iOS and Android) and some of the users are also seeing a discount being offered. This makes the results of the test a bit hard to interpret. <br>\n",
    "\n",
    "Answer the following questions about the experiment:<br>\n",
    "1a. What is the probability that the Challenger is the superior model?<br>\n",
    "1b. Based on your answer to number 1, would you be comfortable deciding yes/no on whether or not to change models?<br>\n",
    "1c. If we decide to switch exclusively to the Challenger model for our iOS users, do we have a reasonable chance at getting 500 purchases in the first 10,000 views? what about 600?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1a:\n",
    "**Assumption#1**: There was no bias in sampling users within Champion and Challenger model groups <br>\n",
    "\n",
    "The outcome for each user's view is not continuous but binary: either \"purchased item\" or \"not purchased item\". A Chi-Square test is beneficial in such scenarios where we can compare the \"purchase rates\" of the two groups to decide if the challenger model is superior as compared to the champion. Hence, I calculated a new column called 'no_purchases'. <br>\n",
    "Note: In the given data the purchase rate is as low as 5% for some cases. Lower rates can cause errors in estimating normal distributions. (Normal distribution is a valid approximation after 10-20 conversions). Hence, I chose Chi-Square. <br>\n",
    "<br>For this experiment:\n",
    "\n",
    "**Null Hypothesis**: There is no difference between the challenger and champion models' purchase rate (and the fact that we observed a difference is due to chance).\n",
    "<br>\n",
    "**Alternative Hypothesis**: The Challenger model has a higher purchase rate than the Champion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_type</th>\n",
       "      <th>variant</th>\n",
       "      <th>discount</th>\n",
       "      <th>total_views</th>\n",
       "      <th>number_of_purchases</th>\n",
       "      <th>no_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>android</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>False</td>\n",
       "      <td>6010</td>\n",
       "      <td>189</td>\n",
       "      <td>5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>android</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>True</td>\n",
       "      <td>331</td>\n",
       "      <td>16</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android</td>\n",
       "      <td>Champion</td>\n",
       "      <td>False</td>\n",
       "      <td>1084</td>\n",
       "      <td>23</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>android</td>\n",
       "      <td>Champion</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>False</td>\n",
       "      <td>6905</td>\n",
       "      <td>336</td>\n",
       "      <td>6569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>True</td>\n",
       "      <td>1986</td>\n",
       "      <td>196</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Champion</td>\n",
       "      <td>False</td>\n",
       "      <td>6576</td>\n",
       "      <td>266</td>\n",
       "      <td>6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Champion</td>\n",
       "      <td>True</td>\n",
       "      <td>2054</td>\n",
       "      <td>161</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device_type     variant  discount  total_views  number_of_purchases  \\\n",
       "0     android  Challenger     False         6010                  189   \n",
       "1     android  Challenger      True          331                   16   \n",
       "2     android    Champion     False         1084                   23   \n",
       "3     android    Champion      True           54                    3   \n",
       "4         iOS  Challenger     False         6905                  336   \n",
       "5         iOS  Challenger      True         1986                  196   \n",
       "6         iOS    Champion     False         6576                  266   \n",
       "7         iOS    Champion      True         2054                  161   \n",
       "\n",
       "   no_purchases  \n",
       "0          5821  \n",
       "1           315  \n",
       "2          1061  \n",
       "3            51  \n",
       "4          6569  \n",
       "5          1790  \n",
       "6          6310  \n",
       "7          1893  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.read_csv(\"ex2_table.csv\")\n",
    "models['no_purchases'] = models['total_views'] - models['number_of_purchases']\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since during the experiment, the users were shown prices from models (champion vs challenger) on different mobile devices (iOS and Android) and with a presence or absence of discounts, these two factors will need to be controlled for while comparing the performance of both models. Controlling for device type and discount gives following 4 cases:<br><br>\n",
    "CASE 1: device type = 'android' and discount = False <br>\n",
    "CASE 2: device type = 'android' and discount = True <br>\n",
    "CASE 3: device type = 'iOS' and discount = False <br>\n",
    "CASE 4: device type = 'iOS' and discount = True <br>\n",
    "\n",
    "Note: \n",
    "1. I will list the detailed steps for Case1. Calculations for the rest of the cases will follow similar logic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 1: device type = 'android' and discount = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_type</th>\n",
       "      <th>variant</th>\n",
       "      <th>discount</th>\n",
       "      <th>total_views</th>\n",
       "      <th>number_of_purchases</th>\n",
       "      <th>no_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>android</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>False</td>\n",
       "      <td>6010</td>\n",
       "      <td>189</td>\n",
       "      <td>5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android</td>\n",
       "      <td>Champion</td>\n",
       "      <td>False</td>\n",
       "      <td>1084</td>\n",
       "      <td>23</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device_type     variant  discount  total_views  number_of_purchases  \\\n",
       "0     android  Challenger     False         6010                  189   \n",
       "2     android    Champion     False         1084                   23   \n",
       "\n",
       "   no_purchases  \n",
       "0          5821  \n",
       "2          1061  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[(models.discount==False) & (models.device_type=='android')]\n",
    "# Following is the observed outcome table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our experiment,<br>\n",
    "H₀: \"the purchase rate is the same for the two models\"<br>\n",
    "H₁: \"the purchase rate is higher for challenger model\"<br>\n",
    "\n",
    "**First step** is to model H₀ which says that both challenger and champion models' purchase rates follow the same Binomial Distribution. Hence, I will derive the theoretical purchase rate for H₀:\n",
    "<br><br>\n",
    "*Step 1:* <br>\n",
    "p-hat = &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;((#challenger purchases) + (#champion purchases)) / <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;((#challenger total_views) + (#champion total_views)) <br><br>\n",
    "p-hat = (189+23)/(6010+1084)<br>\n",
    "p-hat = 0.029 <br><br>\n",
    "*Step 2:*<br>\n",
    "Multiply p-hat with total_views of both models to get theoretical purchase_rates. \n",
    "<br>Thus, under H₀, the theoretical outcome table is: <br>\n",
    "\n",
    "| Variant  | total_views | purchases | no_purchases  |\n",
    "|---|---|---|---|\n",
    "| challenger | 6010 | 175 | 5835 |\n",
    "| champion | 1084 | 31 | 1053 | <br>\n",
    "\n",
    "**Second step** is to see how likely our observed samples are under H₀. For this, I will calculate D (squared relative distance between the theoretical and the observed distributions) and derive its corresponding p-value using Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance d: 3.278885259219726\n",
      "p-value: 0.07017657889158617\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "T_case1 = np.array([175, 31, 5835, 1053])\n",
    "O_case1 = np.array([189, 23, 5821, 1061])\n",
    "\n",
    "D_case1 = np.sum(np.square(T_case1-O_case1)/T_case1)\n",
    "\n",
    "pvalue_case1 = chi2.sf(D_case1, df=1)\n",
    "\n",
    "print(\"distance d: {0}\\np-value: {1}\".format(D_case1,pvalue_case1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CONCLUSION:* P-value is 7%. With α criterion of 5%, we have pvalue>α and H₀ cannot be rejected.<br>Thus, we cannot conclude that challenger model outperforms champion for this case. In other words, with a confidence level of 95% we say that there is **No Significant Difference between the performance of two models.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 2 device type = 'android' and discount = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_type</th>\n",
       "      <th>variant</th>\n",
       "      <th>discount</th>\n",
       "      <th>total_views</th>\n",
       "      <th>number_of_purchases</th>\n",
       "      <th>no_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>android</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>True</td>\n",
       "      <td>331</td>\n",
       "      <td>16</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>android</td>\n",
       "      <td>Champion</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device_type     variant  discount  total_views  number_of_purchases  \\\n",
       "1     android  Challenger      True          331                   16   \n",
       "3     android    Champion      True           54                    3   \n",
       "\n",
       "   no_purchases  \n",
       "1           315  \n",
       "3            51  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[(models.discount==True) & (models.device_type=='android')]\n",
    "# Following is the observed outcome table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First step** I will derive the theoretical purchase rate for H₀:\n",
    "<br><br>\n",
    "*Step 1:* <br>\n",
    "p-hat = (16+3)/(331+54)<br>\n",
    "p-hat = 0.049 <br><br>\n",
    "*Step 2:*<br>\n",
    "Under H₀, the theoretical outcome table is: <br>\n",
    "\n",
    "| Variant  | total_views | number_of_purchases | no_purchases  |\n",
    "|---|---|---|---|\n",
    "| challenger | 331 | 16 | 315 |\n",
    "| champion | 54 | 3 | 51 | <br>\n",
    "\n",
    "**Second step** is to see how likely our observed samples are under H₀. For this, I will calculate D (squared relative distance between the theoretical and the observed distributions) and derive its corresponding p-value using Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance d: 0.0\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "T_case2 = np.array([16, 3, 315, 51])\n",
    "O_case2 = np.array([16, 3, 315, 51])\n",
    "\n",
    "D_case2 = np.sum(np.square(T_case2-O_case2)/T_case2)\n",
    "\n",
    "pvalue_case2 = chi2.sf(D_case2, df=1)\n",
    "\n",
    "print(\"distance d: {0}\\np-value: {1}\".format(D_case2,pvalue_case2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CONCLUSION:* P-value is 100%. With α criterion of 5%, we have pvalue>α and H₀ cannot be rejected. Even though the distance between theoretical and observed distributions is 0, p-value 100% suggests that the d=0 might be purely by chance. <br>Thus, we cannot conclude that challenger model outperforms champion for this case. In other words, with a confidence level of 95% we say that there is **No Significant Difference between the performance of two models.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 3 device type = 'iOS' and discount = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_type</th>\n",
       "      <th>variant</th>\n",
       "      <th>discount</th>\n",
       "      <th>total_views</th>\n",
       "      <th>number_of_purchases</th>\n",
       "      <th>no_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>False</td>\n",
       "      <td>6905</td>\n",
       "      <td>336</td>\n",
       "      <td>6569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Champion</td>\n",
       "      <td>False</td>\n",
       "      <td>6576</td>\n",
       "      <td>266</td>\n",
       "      <td>6310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device_type     variant  discount  total_views  number_of_purchases  \\\n",
       "4         iOS  Challenger     False         6905                  336   \n",
       "6         iOS    Champion     False         6576                  266   \n",
       "\n",
       "   no_purchases  \n",
       "4          6569  \n",
       "6          6310  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[(models.discount==False) & (models.device_type=='iOS')]\n",
    "# Following is the observed outcome table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First step** I will derive the theoretical purchase rate for H₀:\n",
    "<br><br>\n",
    "*Step 1:* <br>\n",
    "p-hat = (336+266)/(6905+6576)<br>\n",
    "p-hat = 0.045 <br><br>\n",
    "*Step 2:*<br>\n",
    "Under H₀, the theoretical outcome table is: <br>\n",
    "\n",
    "| Variant  | total_views | number_of_purchases | no_purchases  |\n",
    "|---|---|---|---|\n",
    "| challenger | 6905 | 311 | 6594 |\n",
    "| champion | 6576 | 296 | 6280 | <br>\n",
    "\n",
    "**Second step** is to see how likely our observed samples are under H₀. For this, I will calculate D (squared relative distance between the theoretical and the observed distributions) and derive its corresponding p-value using Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance d: 5.2882820808865825\n",
      "p-value: 0.021469388921317587\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "T_case3 = np.array([311, 296, 6594, 6280])\n",
    "O_case3 = np.array([336, 266, 6569, 6310])\n",
    "\n",
    "D_case3 = np.sum(np.square(T_case3 - O_case3)/T_case3)\n",
    "\n",
    "pvalue_case3 = chi2.sf(D_case3, df=1)\n",
    "\n",
    "print(\"distance d: {0}\\np-value: {1}\".format(D_case3, pvalue_case3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CONCLUSION:* With α criterion of 5%, we have pvalue < α and H₀ can be rejected. <br>Thus, we conclude that with a confidence level of 95%, **the challenger model outperforms champion in this case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 4 device type = 'iOS' and discount = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_type</th>\n",
       "      <th>variant</th>\n",
       "      <th>discount</th>\n",
       "      <th>total_views</th>\n",
       "      <th>number_of_purchases</th>\n",
       "      <th>no_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Challenger</td>\n",
       "      <td>True</td>\n",
       "      <td>1986</td>\n",
       "      <td>196</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Champion</td>\n",
       "      <td>True</td>\n",
       "      <td>2054</td>\n",
       "      <td>161</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device_type     variant  discount  total_views  number_of_purchases  \\\n",
       "5         iOS  Challenger      True         1986                  196   \n",
       "7         iOS    Champion      True         2054                  161   \n",
       "\n",
       "   no_purchases  \n",
       "5          1790  \n",
       "7          1893  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[(models.discount==True) & (models.device_type=='iOS')]\n",
    "# Following is the observed outcome table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First step** I will derive the theoretical purchase rate for H₀:\n",
    "<br><br>\n",
    "*Step 1:* <br>\n",
    "p-hat = (196+161)/(1986+2054)<br>\n",
    "p-hat = 0.088 <br><br>\n",
    "*Step 2:*<br>\n",
    "Under H₀, the theoretical outcome table is: <br>\n",
    "\n",
    "| Variant  | total_views | number_of_purchases | no_purchases  |\n",
    "|---|---|---|---|\n",
    "| challenger | 1986 | 175 | 1811 |\n",
    "| champion | 2054 | 181 | 1873 | <br>\n",
    "\n",
    "**Second step** is to see how likely our observed samples are under H₀. For this, I will calculate D (squared relative distance between the theoretical and the observed distributions) and derive its corresponding p-value using Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance d: 5.187017755149196\n",
      "p-value: 0.022756233967973202\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "T_case4 = np.array([175, 181, 1811, 1873])\n",
    "O_case4 = np.array([196, 161, 1790, 1893])\n",
    "\n",
    "D_case4 = np.sum(np.square(T_case4 - O_case4)/T_case4)\n",
    "\n",
    "pvalue_case4 = chi2.sf(D_case4, df=1)\n",
    "\n",
    "print(\"distance d: {0}\\np-value: {1}\".format(D_case4, pvalue_case4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CONCLUSION:* With α criterion of 5%, we have pvalue < α and H₀ can be rejected. <br>Thus, we conclude that with a confidence level of 95%, **the challenger model outperforms champion in this case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1a.\n",
    "To summarize: <br>\n",
    "For device type = 'android' regardless of discount, there is not sufficient evidence to conclude that Challenger is the superiod model<br>\n",
    "For device type = 'iOS' for both discount=True/False, there is roughly 98% probability that Challenger is the superior model.<br>\n",
    "\n",
    "### Answer 1b. \n",
    "I would not be comfortable to change models to Challenger across all users (iOS + android devices)<br>\n",
    "\n",
    "### Answer 1c.\n",
    "**Assumption#1**: I will assess the chance of getting *atleast* 500 purchases in 10,000 view and *atleast* 600 purchases in 10,000 view<br>\n",
    "It should be noted the iOS users who are offered discount are more likely to purchase an item as compared to the users who are not shown the discount. Hence, I will separately assess (for two groups: discount = True/False) whether we have a reasonable chance at getting 500 purchases in first 10,000 views and 600 in 10,000 views<br>\n",
    "\n",
    "Steps - \n",
    "1. Calculate observed purchase rate from given data :: # of purchases/total_views\n",
    "2. Calculate standard deviation from given data :: sqrt(p*(1-p)/n)\n",
    "3. Calculate z-score of new purchases rates (500/10000 = 5% and 600/10000 = 6%)\n",
    "4. Calculate probability for z-score\n",
    "5. Conclude if we have reasonable chance\n",
    "<br>\n",
    "Alternatively, in a naive linear projection approach:\n",
    "1. Multiply the observed 4.87% rate with 10,000 we get a projection of 487 purchases. \n",
    "2. Multiply the observed 9.87% rate with 10,000 we get a projection of 987 purchases. \n",
    "Hence, I will compare the 500 and 600 prize freeze goals with above projections. \n",
    "<br>\n",
    "\n",
    "| Variant  | Discount | Observed purchases rate | Std. deviation  | New purchases |New purchases rate | Conclusion |\n",
    "|---|---|---|---|---|---|---|\n",
    "| challenger | False | 4.87% | 0.26% | 500 in 10,000 views | 5% | Z-score = 0.5. Probability of new purchase rate = 30%. Linear Projection: 487 purchases, falls short of the required 500. Thus, **we dont** have a reasonable chance |\n",
    "| challenger | True | 9.87% | 0.48% | 500 in 10,000 views | 5% | Z-score = -10.145. Probability of new purchase rate = 100%. Linear Projection: 987 purchases, exceeds the required 500. Thus, **we have** a reasonable chance |\n",
    "| challenger | False | 4.87% | 0.26% | 600 in 10,000 views | 6% | Z-score = 4.346. Probability of new purchase rate = 0.001%. Linear Projection: 487 purchases, falls short of the required 600. Thus, we **dont have** a reasonable chance  |\n",
    "| challenger | True | 9.87% | 0.48% | 600 in 10,000 views | 6% | Z-score = -8.062. Probability of new purchase rate = 100%. Linear Projection: 987 purchases, exceeds the required 600. Thus, **we have** a reasonable chance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a mathematical model of a user’s “purchase interaction” which can be described as a collection of searches. Our users are beginners who want to get into the planting game. Hence, they seldom make their purchases in the very first search. This requires us to represent this non-numeric search data such that we can draw quantitative conclusions.<br><br>\n",
    "2a. How would you transform the collection of searches into a numeric vector representing a purchase?<br>\n",
    "&nbsp;&nbsp;- Assume that we have hundreds of thousands of users and we want to represent all of their purchases this way.<br>\n",
    "&nbsp;&nbsp;- We ideally want this to be a general representation we could use in multiple modeling projects, but we definitely care about finding similar purchases.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For confidentiality reasons, I will be not be able to show the data for this part of the exercise. Hence, I have listed the data definition in detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data definition:**\n",
    "<pre>\n",
    "User ID                          Unique customer account Id\n",
    "Purchase_Item                    Item the customer searched for\n",
    "First Searched Date              Date of first search\n",
    "Purchase Date                    Date of actual purchase\n",
    "Purchase Type                    One-time purchase or Subscription \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2a:\n",
    "\n",
    "| Variable  | Type | Description | Transformation  |\n",
    "|---|---|---|---|\n",
    "| purchase_id | New | Primary key representing each purchase | Generate unique numbers |\n",
    "| user_id | Existing | Unique user id | N/A |\n",
    "| purchase_type_one_time  | Derived | value = 1 when one time purchase else 0 | One-hot encode existing 'Purchase Type' column using pandas.get_dummies() |\n",
    "| purchase_type_subscription | Derived | value = 1 when one way trip else 0  | One-hot encode existing 'Purchase Type' column using pandas.get_dummies() |\n",
    "| item_category | Derived | Items represented as numbers | Label encode - give numerical value for each label |\n",
    "| search_frequency | New | Number of times user searched for item | For each user, group by items & count records |\n",
    "| first_searched_year | Derived | first search year | Transform using pandas datetime package: trips['first_searched_dt'].dt.year |\n",
    "| first_searched_month | Derived | first search month | trips['first_searched_dt'].dt.month |\n",
    "| first_searched_week | Derived | first search week | trips['first_searched_dt'].dt.week |\n",
    "| first_searched_day | Derived | first search day of month | trips['first_searched_dt'].dt.day |\n",
    "| first_searched_hour | Derived | first search hour | trips['first_searched_dt'].dt.hour |\n",
    "| first_searched_dayofweek | Derived | first search day of week | trips['first_searched_dt'].dt.dayofweek |\n",
    "| purchase_year | Derived | departure year | trips['departure_date'].dt.year |\n",
    "| purchase_month | Derived | departure month | trips['departure_date'].dt.month |\n",
    "| purchase_week | Derived | departure week | trips['departure_date'].dt.week |\n",
    "| purchase_day | Derived | departure day of month | trips['departure_date'].dt.day |\n",
    "| purchase_dayofweek | Derived | departure day of week | trips['departure_date'].dt.dayofweek |\n",
    "\n",
    "<br>\n",
    "\n",
    "*A lot of interesting analyses can be performed with above numerical vector and can be used for multiple modeling projects*:\n",
    "1. purchase_window: Calculate difference between first_searched_dt and purchase_date\n",
    "2. frequency of purchases being done in weekend vs weekdays\n",
    "3. user's preference for searching/shopping (after work at a specific hour, at a specific day of the week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Experiments and Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the core features of our website is that we advise our customers on whether to buy a subscription now or wait for the weather (temperature) to go down and purchase later. Our recommendations are critical for users because the types of plants we sell are very sensitive to the weather and will die within days if the weather conditions are not favourable. <br>\n",
    "But what if our buy recommendation is wrong and the weather in fact worsens after the user subscribes to our service?  To lower the pain when this happens we refund users a certain % of their purchased amount if the weather worsens after they buy.\n",
    "If you were the data scientist in charge of this project what information would you want to track to decide whether this recommendation feature is successful? What would you track to determine how to improve this feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3:\n",
    "This question can be thought of in terms of the following four scenarios. These scenarios are the outcome of buy/wait recommendation:<br>\n",
    "shown_weather &#8594; buy &#8594; weather becomes pleasant : True positive &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(correctly recommended buy at best weather conditions) <br>\n",
    "shown_weather &#8594; buy &#8594; weather worsens: **False Positive** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(incorrectly recommended a positive action i.e. buy, when weather actually worsened)<br>\n",
    "shown_weather &#8594; wait &#8594; weather worsense: True negative &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(correctly recommended wait and weather actually went worsened)<br>\n",
    "shown_weather &#8594; wait &#8594; weather becomes pleasant: False negative &nbsp;&nbsp;&nbsp;(incorrectly recommended wait. Weather became pleasant instead of worse)\n",
    "<br><br>\n",
    "False Positive scenario above would trigger our refund action mentioned above. Success of this feature may mean multiple things. I would define it as follows:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;A. Suppose we have $1,000,000 budget for paying out all refunds in above scenarios. Then, all pay-outs should be maintained within budget<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;B. Ensure customers do not churn \n",
    "\n",
    "For point#A, I would track below metrics: \n",
    "1. Total Type I error cost = sum of all refund payouts. Goal is to maintain this figure below $1,000,000\n",
    "2. % of cases where refund in above false positive scenario was triggered = (# refunds)/(total # transactions)x100. Goal is to minimize this metric, indicating the frequency of correct recommendations and no customer hassle.\n",
    "3. Standard deviation of amount of refund payout = STD(all refund payouts). Goal is to minimize this metric, indicating low variance in incorrect cost estimations. <br>\n",
    "\n",
    "For point#B, I would track below metrics: <br>\n",
    "1. Customer churn rate = (customers lost after refund interactions in a quarter)/(# customers at start of quarter). Note: the numerator will need to be controlled for other churn factors\n",
    "2. If customer feedback/ratings are available, measure positive and negative sentiment rate.\n",
    "<br>\n",
    "Note: Additionally Type II error (false negative) might occur when wait recommendation is given but the weather becomes pleasant. To calculate cost of this error, I would look at the churn rate of customers waiting upto a certain time period after obeying the wait recommendation. But, not interacting with the app for further business.  \n",
    "<br>\n",
    "\n",
    "To improve this feature:\n",
    "1. I would slowly and iteratively lower the % of the fare difference to be paid out by us and track customer sentiment and churn rate. Goal here is to minimize the amount to be paid out, ensuring we meet the budget while not losing customers. \n",
    "2. I would put a floor to the refund payout i.e. if the refund payout is greater than or equal to 50, only then a payout is eligible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Programming\n",
    "Given the table of our warehouses and their locations (in latitude and longitude) below, write a function that takes a city code as input and returns the warehouses listed from nearest to furthest from the input city. This is for connecting user shipments from nearest warehouses when items are not available in the user's input city warehouse or when user is order from a city which does not have our warehouse. <br>\n",
    "Use only the basic libraries (using sorting functions/methods provided by the standard library is definitely fine).\n",
    "\n",
    "### Answer 4:\n",
    "**Assumption#1**: Output should not return the input city itself as the first nearest element in the list <br>\n",
    "**Assumption#2**: Nearest/farthest distances can be calculated using the shortest distance between two points on earth's surface using Haversine equation which results in 0.5% error <br>\n",
    "**Assumption#3**: If  city code, other than the 8 codes listed in the dataframe below are provided as input, return error message <br>\n",
    "**Assumption#4**: Given latitude, longitude are in degrees. Hence, convert to radians for calculating distance using Haversine formula in Python <br>\n",
    "<br>*References:*<br>\n",
    "Haversine formula - https://www.movable-type.co.uk/scripts/latlong.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Code</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDG</td>\n",
       "      <td>49.012798</td>\n",
       "      <td>2.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHC</td>\n",
       "      <td>-43.489399</td>\n",
       "      <td>172.531998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DYR</td>\n",
       "      <td>64.734901</td>\n",
       "      <td>177.740997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EWR</td>\n",
       "      <td>40.692501</td>\n",
       "      <td>-74.168701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HNL</td>\n",
       "      <td>21.318701</td>\n",
       "      <td>-157.921997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OME</td>\n",
       "      <td>64.512199</td>\n",
       "      <td>-165.445007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ONU</td>\n",
       "      <td>-20.650000</td>\n",
       "      <td>-178.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PEK</td>\n",
       "      <td>40.080101</td>\n",
       "      <td>116.584999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City Code        Lat        Long\n",
       "0       CDG  49.012798    2.550000\n",
       "1       CHC -43.489399  172.531998\n",
       "2       DYR  64.734901  177.740997\n",
       "3       EWR  40.692501  -74.168701\n",
       "4       HNL  21.318701 -157.921997\n",
       "5       OME  64.512199 -165.445007\n",
       "6       ONU -20.650000 -178.699997\n",
       "7       PEK  40.080101  116.584999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = pd.read_csv(\"ex1_table.csv\") \n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\" Function takes lat/lon coordinates for origin and destination airports and calculates distance between them\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dist : float\n",
    "    \"\"\"\n",
    "    # approximate radius of earth in miles\n",
    "    R = 3958.8 \n",
    "    # given latitudes and longitudes are in degrees, convert them to radians\n",
    "    lat1 = radians(lat1) \n",
    "    lon1 = radians(lon1) \n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)  \n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    dist = R * c\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to furthest warehouses from the input city are:\n",
      "EWR\n",
      "OME\n",
      "DYR\n",
      "PEK\n",
      "HNL\n",
      "ONU\n",
      "CHC\n"
     ]
    }
   ],
   "source": [
    "def warehouse_proximity(city_code):\n",
    "    \"\"\" Function takes an airport code as input and returns the airports listed from nearest to furthest from the input\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    airport_code : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    airport_output : list\n",
    "    \"\"\"\n",
    "    \n",
    "    # check if airport code present in the dataframe read from file\n",
    "    assert city_code in city['City Code'].values, \"Sorry, input out of scope\"\n",
    "    \n",
    "    # fetch input airport's location\n",
    "    input_lat = city.loc[city['City Code'] == city_code]['Lat']\n",
    "    input_lon = city.loc[city['City Code'] == city_code]['Long']\n",
    "    \n",
    "    # calculate distance of each airport from input and sort\n",
    "    city['distance'] = city.apply(lambda row : distance(input_lat, input_lon, row['Lat'], row['Long']), axis = 1)\n",
    "    city_output = city.sort_values(by='distance')\n",
    "    \n",
    "    # fetch the airport names from the sorted list and return\n",
    "    city_output = city_output.iloc[1:,0].tolist()\n",
    "    return city_output\n",
    "\n",
    "# Test the function here:\n",
    "output_df = warehouse_proximity('CDG')\n",
    "print(\"Nearest to furthest warehouses from the input city are:\")\n",
    "print(*output_df, sep = \"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
